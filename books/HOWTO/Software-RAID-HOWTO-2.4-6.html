<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
 <META NAME="GENERATOR" CONTENT="SGML-Tools 1.0.9">
 <TITLE>The Software-RAID HOWTO: Реконструкция</TITLE>
 <LINK HREF="Software-RAID-HOWTO-2.4-7.html" REL=next>
 <LINK HREF="Software-RAID-HOWTO-2.4-5.html" REL=previous>
 <LINK HREF="Software-RAID-HOWTO-2.4.html#toc6" REL=contents>
</HEAD>
<BODY>
<A HREF="Software-RAID-HOWTO-2.4-7.html">Next</A>
<A HREF="Software-RAID-HOWTO-2.4-5.html">Previous</A>
<A HREF="Software-RAID-HOWTO-2.4.html#toc6">Contents</A>
<HR>
<H2><A NAME="s6">6. Реконструкция</A></H2>

<P>Если Вы читали другие части этого HOWTO, Вы должны уже хорошо представлять 
как вызывается реконструкция деградировавшего RAID. Я обобщаю: 
<UL>
<LI>Выключаем систему</LI>
<LI>Заменяем отказавший диск</LI>
<LI>Включаем систему снова.</LI>
<LI>Используем <CODE>raidhotadd /dev/mdX /dev/sdX</CODE> для добавления диска 
в массив</LI>
<LI>Пьем кофе, пока работает автоматическая реконструкция</LI>
</UL>

И это так.
<P>Итак, обычно это так, пока Вам не повезет и Ваш RAID станет нерабочим из-за 
отказа более одного диска. Это может фактически случиться, если у Вас 
несколько дисков на одной шине, и один диск захватит шину при отказе. 
Другие диски, в порядке, но будут недоступны для RAID уровня, так как шина 
блокирована, и они будут помечены как отказавшие.  На RAID-5, где у Вас может 
быть резервный диск, потеря двух или более дисков может быть фатальной.
<P>Следующая секция - объяснение, которое прислал мне Martin Bene,
и описал возможность восстановления при жутком сценарии описанном выше. 
Это использует директиву <CODE>failed-disk</CODE> в Вашем <CODE>/etc/raidtab</CODE>, таким образом
это будет работать с ядрами 2.2.10 и выше.
<P>
<H2><A NAME="ss6.1">6.1 Восстановление при множественных отказах диска</A>
</H2>

<P>Сценарий таков:
<UL>
<LI>Контроллер умирает и отключает два диска одновременно,</LI>
<LI>Все диски на одной scsi шине могут быть недоступны, если отказывает диск,</LI>
<LI>Отсоединяется кабель...</LI>
</UL>

Коротко: довольно часто у Вас <EM>временный отказ</EM> нескольких дисков 
одновременно; в последствии суперблоки RAID не синхронизированы и Вы уже не 
можете инициализировать Ваш RAID массив.
<P>Остается одно: перезаписать суперблоки RAID подав <CODE>mkraid --force</CODE>
<P>Чтобы это сделать, Вам нужно иметь свежий <CODE>/etc/raidtab</CODE> - если 
он <B>НЕ ТОЧНО</B> соответствует устройствам и исходному порядку 
дисков, это не сработает.
<P>Посмотрите в sylog на результат попытки запуска массива, Вы увидите 
отсчет событий для каждого суперблока; обычно лучше оставить диск с наименьшим
отсчетом события, т.е. с самым старым.
<P>Если Вы делаете <CODE>mkraid</CODE> без <CODE>failed-disk</CODE>, нить восстановления
немедленно выругается и начнет перестроение блоков паритета
- не то, что Вам сейчас нужно.
<P>С <CODE>failed-disk</CODE>, В можете точно указать какие диски Вы хотите 
активировать и, возможно, попробовать различные комбинации для лучшего 
результата. Подсказка, при этих экспериментах монтируете систему в режиме 
только для чтения... Это было успешно использовано, по крайней мере, двумя
парнями, с которыми я контактировал.
<P>
<P>
<HR>
<A HREF="Software-RAID-HOWTO-2.4-7.html">Next</A>
<A HREF="Software-RAID-HOWTO-2.4-5.html">Previous</A>
<A HREF="Software-RAID-HOWTO-2.4.html#toc6">Contents</A>
</BODY>
</HTML>
