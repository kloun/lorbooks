<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
 <META NAME="GENERATOR" CONTENT="SGML-Tools 1.0.9">
 <TITLE>Software-RAID HOWTO: Восстановление ошибок</TITLE>
 <LINK HREF="Software-RAID-HOWTO-2.2-5.html" REL=next>
 <LINK HREF="Software-RAID-HOWTO-2.2-3.html" REL=previous>
 <LINK HREF="Software-RAID-HOWTO-2.2.html#toc4" REL=contents>
</HEAD>
<BODY>
<A HREF="Software-RAID-HOWTO-2.2-5.html">Next</A>
<A HREF="Software-RAID-HOWTO-2.2-3.html">Previous</A>
<A HREF="Software-RAID-HOWTO-2.2.html#toc4">Contents</A>
<HR>
<H2><A NAME="s4">4. Восстановление ошибок</A></H2>

<P>
<OL>
<LI><B>В</B>:
У меня установлен RAID-1 (зеркализация), и у меня пропало питание во время дисковой активности.
Что мне теперь делать?

<BLOCKQUOTE>
<B>О</B>:
Избыточность уровней RAID предназначена для защиты от отказа
<B>диска</B>, не от отказа <B>питания</B>.

Есть несколько путей восстановления в этой ситуации.
        
<UL>
<LI>Метод (1): Использовать raid утилиты. Он может быть 
использован для синхронизации raid массивов. Он не устраняет 
повреждение файловой системы; после синхронизации raid 
массивов, файловая система все еще нуждается в исправлении с 
помощью fsck.  Raid массивы могут быть проверены 
<CODE>ckraid /etc/raid1.conf</CODE> (для RAID-1, или,
<CODE>/etc/raid5.conf</CODE>, и т.д..)
                
Запуск <CODE>ckraid /etc/raid1.conf --fix</CODE> выберет оин 
один диск из дисков массива (обычно первый), для 
использования его в качестве главной копии, и копирования его 
блоков на другие диски зеркала.
Для обозначения диска, который должен быть использован как 
главный, вы можете использовать <CODE>--force-source</CODE> флаг: 
например,
<CODE>ckraid /etc/raid1.conf --fix --force-source /dev/hdc3</CODE>.
Комманда ckraid может быть безопасно запущена без опции 
<CODE>--fix</CODE>
для проверки неактивного RAID массива без внесения изменений.
Если Вы удовлетворены предполагаемыми изменениями, примените 
опцию
<CODE>--fix</CODE> .
           </LI>
<LI>Метод (2): Параноидальный, длительный по времени, не 
намного лучше, чем первый путь.
Представим двух-дисковый массив RAID-1, состоящий из разделов
<CODE>/dev/hda3</CODE> и <CODE>/dev/hdc3</CODE>.  Вы можете
попробовать следующее:
<OL>
<LI><CODE>fsck /dev/hda3</CODE></LI>
<LI><CODE>fsck /dev/hdc3</CODE></LI>
<LI>Решите, который из двух разделов содержит меньше
ошибок, или где проще восстановление, или на котором
находятся нужные Вам данные.  Выберите один, 
только один, для вашей новой ``главной'' копии.  
Предположим Вы выбрали <CODE>/dev/hdc3</CODE>.</LI>
<LI><CODE>dd if=/dev/hdc3 of=/dev/hda3</CODE></LI>
<LI><CODE>mkraid raid1.conf -f --only-superblock</CODE></LI>
</OL>


Вместо последних двух шагов, Вы можете запустить
<CODE>ckraid /etc/raid1.conf --fix --force-source /dev/hdc3</CODE>,
что будет быстрее.
</LI>
<LI>Метод (3): Версия для ленивых людей.  Если Вы не хотите ждать
завершения долгой проверки fsck, просто пропустите
первые три шага выше, и начинайте прямо с последних двух шагов.
Только после завершения запустите <CODE>fsck /dev/md0</CODE>.
Метод (3) на самом деле замаскированный метод (1).</LI>
</UL>


В любом случае, вышеуказанные шаги только синхронизируют массив raid.
Для файловых систем возможно все еще необходимо устранение ошибок: 
для этого, нужно запустить fsck на активном, но не смонтированном 
устройстве.

<P>С трех-дисковым массивом RAID-1, есть много вариантов,
таких как использование двух дисков для выбора ответа.
Утилиты автоматизации этого пока (Сентябрь 97) не существуют.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Если у меня установлен RAID-4 или RAID-5 (паритетный), и пропало питание во врем активности диска.
Что мне делать?

<BLOCKQUOTE>
<B>О</B>:
Избыточность уровней RAID предназначена для защиты от отказов
<B>дисков</B>, а не от отказов <B>питания</B>.

Так как диски в массиве RAID-4 или RAID-5 не содержат файловой системы,
которую fsck может читать, есть несколько опций восстановления.  Вы
не можете использовать fsck для предварительной проверки и/или 
восстановления; Вы должны использовать сначала ckraid.
<P>Комманда <CODE>ckraid</CODE> может быть безопасно запущена без опции <CODE>--fix</CODE>
для проверки неактивного массива RAID без внесения любых изменений.
Когда Вы удовлетворены предложенными изменениями, примените опцию
<CODE>--fix</CODE>.
<P>
<P>Если Вы хотите, Вы можете попробовать обозначить один из дисков как ''отказавший диск''.
Делайте это с флагом <CODE>--suggest-failed-disk-mask</CODE>.
<P>Только один бит должен быть установлен в флаге: RAID-5 не может восстанавливать два
отказавших диска.
mask - битовая маска: итак:
<PRE>
    0x1 == первый диск
    0x2 == второй диск
    0x4 == третий диск
    0x8 == четвертый диск, и т.д.
            
</PRE>
<P>Или Вы можете выбрать модификацию секторов с паритетом, используя
флаг <CODE>--suggest-fix-parity</CODE> flag.  Это заново вычислит 
паритет из других секторов.
<P>
<P>Флаг <CODE>--suggest-failed-dsk-mask</CODE> и
<CODE>--suggest-fix-parity</CODE>
может быть безопасно использован для проверки. Никаких изменений не 
будет сделано, если не указан флаг <CODE>--fix</CODE>.  Итак, Вы можете 
экспериментировать с различными возможными вариантами восстановления.
<P>
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Мое RAID-1 устройство, <CODE>/dev/md0</CODE> состоит из двух разделов 
жестких дисков:
<CODE>/dev/hda3</CODE> и <CODE>/dev/hdc3</CODE>.
Недавно, диск с <CODE>/dev/hdc3</CODE> отказал,
был заменен на новый диск.  Мой лучший друг,
который не разбирается в RAID, сказал, что сейчас правильно сделать
''<CODE>dd if=/dev/hda3 of=/dev/hdc3</CODE>''.
Я попробовал это, но все по прежнему не работает.

<BLOCKQUOTE>
<B>О</B>:
Вы должны отстранить Вашего друга от компьютера.
К счастью, не произошло никаких серьезных повреждений.
Вы можете все восстановить запустив:
<BLOCKQUOTE><CODE>
<PRE>
mkraid raid1.conf -f --only-superblock
            
</PRE>
</CODE></BLOCKQUOTE>

При запуске <CODE>dd</CODE>, были созданы две идентичные копии раздела.
Это почти правильно, исключая то, что расширение ядра RAID-1
предполагает различие в  суперблоке.
Итак, когда Вы пробуете активировать RAID, программа обратит 
внимание на проблему,
и деактивирует один из двух разделов.
Пересоздав суперблок, вы должны получить полностью рабочую систему.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
У моей версии <CODE>mkraid</CODE> нет флага
<CODE>--only-superblock</CODE>.  Что мне делать?
<BLOCKQUOTE>
<B>О</B>:
В новых утилитах убрали поддержку этого флага, заменив его флагом
<CODE>--force-resync</CODE>.  Как мне сообщили с последней версией 
утилит и программ работает такая последовательность:
<BLOCKQUOTE><CODE>
<PRE>
  umount /web (что было смонтировано на /dev/md0)
  raidstop /dev/md0
  mkraid /dev/md0 --force-resync --really-force
  raidstart /dev/md0
            
</PRE>
</CODE></BLOCKQUOTE>

После этого, <CODE>cat /proc/mdstat</CODE> должно доложить
<CODE>resync in progress</CODE>, и далее можно
<CODE>mount /dev/md0</CODE> с этого места.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Мое устройство RAID-1, <CODE>/dev/md0</CODE> состоит из двух
разделов: <CODE>/dev/hda3</CODE> and <CODE>/dev/hdc3</CODE>.
Мой лучший друг(подруга?), который не разбирается в RAID, 
запустил без меня <CODE>fsck</CODE> на <CODE>/dev/hda3</CODE>,
и сейчас RAID не работает. Что я должен делать?

<BLOCKQUOTE>
<B>О</B>:
Вы должны пересмотреть свое понятие - ``лучший друг''.
В общем, <CODE>fsck</CODE> не должна запускаться на отдельных разделах 
массива RAID.
Предположим ни один из разделов тяжело не поврежден,
потерь данных нет, и RAID-1 устройство может быть восстановлено так:
<OL>
<LI>делаем резервную копию файловой системы на <CODE>/dev/hda3</CODE></LI>
<LI><CODE>dd if=/dev/hda3 of=/dev/hdc3</CODE></LI>
<LI><CODE>mkraid raid1.conf -f --only-superblock</CODE></LI>
</OL>

Это должно вернуть ваше зеркало к работе.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Почему сказанное выше работает как восстанавливающая процедура?
<BLOCKQUOTE>
<B>О</B>:
Потому что каждый компонент раздела в RAID-1 зеркале
является просто точной копией файловой системы.  В крайнем
случае, зеркализация может быть запрещена, и один из разделов
может быть смонтирован и безопасно запущен как обычная, не-RAID
файловая система. Если Вы готовы перезапуститься используя RAID-1,
то демонтируйте раздел, и следуйте вышеприведенным инструкциям 
для восстановления зеркала. Заметьте, что вышеуказанное работает 
ТОЛЬКО для RAID-1, и ни для какого другого уровня.

<P>Возможно, Вам удобнее изменить направление копирования: 
копировать  <B>с</B> диска, который был нетронут
<B>на</B> тот, который был.  Просто будьте уверены, что 
после этого запускаете fsck на md.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Я смущен предыдущим вопросом, но еще не убежден.
Безопасно ли запускать <CODE>fsck /dev/md0</CODE> ?

<BLOCKQUOTE>
<B>О</B>:
Да, безопасно запускать <CODE>fsck</CODE> на устройствах <CODE>md</CODE>.
Фактически, это <B>единственное</B> безопасное место
запуска <CODE>fsck</CODE>.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Если диск медленно слабеет, будет очевидно который из них?
Я беспокоюсь чтобы этого не случилось, и эта неразбериха не  
привела к каким-либо опасным решениям системного администратора.

<BLOCKQUOTE>
<B>О</B>:
Как только диск откажет, драйвер нижнего уровня вернет код
ошибки драйверу RAID.
RAID драйвер пометит этот диск в суперблоках RAID хороших дисков 
как ``плохой''(bad) (таким образом позже мы сможем узнать, которые из
дисков хорошие, а которые нет), и продолжит работу RAID на 
оставшихся действующих зеркалах.

<P>Это, конечно, предполагает, что диск и драйвер нижнего уровня в 
состоянии обнаружить ошибки чтения/записи и не будут, к примеру, 
молча искажать данные. Это справедливо для текущих дисков
(схем обнаружения ошибок используемых в них), и основы работы RAID.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Как насчет горячей замены?

<BLOCKQUOTE>
<B>О</B>:
Работа далека от завершения ``горячей замены''.
С этим свойством, можно добавить несколько ``резервных'' дисков в
RAID набор (уровня 1 или 4/5), и как только диск отказал,
он будет воссоздан на ходу на одном из резервных дисков,
без необходимости остановки массива.

<P>Однако, для использования этого свойства, резервные диски должны 
быть определены на момент загрузки или должны добавляться на ходу,
что требует использования специального шкафа и соединителей,
которые позволяют добавлять диск при включенном питании.  
<P>
<P>На Октябрь 97, доступна бета версия MD, которая позволяет:
<UL>
<LI>RAID 1 и 5 восстановление на резервных дисках</LI>
<LI>RAID-5 восстановление паритета после неправильного
завершения</LI>
<LI>добавление резервных дисков в уже работающий массив 
RAID 1 или 4/5 </LI>
</UL>

По умолчанию, автоматическая реконструкция сейчас (Декабрь 97) 
запрещена по умолчанию, в основном по причине предварительного
характера этой работы.  Она может быть включена изменением значения
<CODE>SUPPORT_RECONSTRUCTION</CODE> в
<CODE>include/linux/md.h</CODE>.  
<P>
<P>Если при создании в массиве сконфигурированы резервные диски и 
реконструкция в ядре включена, резервный диск уже будет содержать 
суперблок (записанный утилитой <CODE>mkraid</CODE>), и ядро будет  
реконструировать его содержимое автоматически (без необходимости 
шагов: вызов <CODE>mdstop</CODE>, замены диска, <CODE>ckraid</CODE>,
<CODE>mdrun</CODE>).
<P>
<P>Если Вы не запустили автоматическую реконструкцию, и не 
сконфигурировали диски с горячей заменой, рекомендуется  процедура
описанная Gadi Oxman
&lt;
<A HREF="mailto:gadio@netvision.net.il">gadio@netvision.net.il</A>&gt;
:
<UL>
<LI>Сейчас, как только один диск удален, набор RAID будет запущен в
деградированном режиме. Для восстановления полноценного 
функционирования, Вы должны:
<UL>
<LI>остановить массив (<CODE>mdstop /dev/md0</CODE>)</LI>
<LI>заменить отказавший диск </LI>
<LI>запустить <CODE>ckraid raid.conf</CODE> для реконструкции 
содержимого</LI>
<LI>запустить массив снова (<CODE>mdadd</CODE>, <CODE>mdrun</CODE>).</LI>
</UL>

Теперь массив будет запущен со всеми дисками,
и снова будет защищен от отказа одного диска.</LI>
</UL>
<P>На текущий момент, не возможно назначить один резервный диск 
нескольким массивам.  Каждый массив требует своего собственного 
резервного диска.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Хочу звуковую сигнализацию 
``один диск в зеркале неисправен'',
так как администратору-новичку узнать это проблематично.

<BLOCKQUOTE>
<B>О</B>:
Ядро ведет протокол событий с 
``<CODE>KERN_ALERT</CODE>'' приоритетом в syslog.
Существует несколько программных пакетов, которые наблюдают за 
файлами syslog, и автоматически подают сигнал на PC динамик, 
звонят на пейджер, посылают почту, и т.д.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Как мне запустить RAID-5 в деградированном режиме
(о одним отказавшим, и еще не замененным диском)?

<BLOCKQUOTE>
<B>О</B>:
Gadi Oxman
&lt;
<A HREF="mailto:gadio@netvision.net.il">gadio@netvision.net.il</A>&gt;
пишет:
Обычно, для запуска RAID-5 набора из n дисков вы должны:
<BLOCKQUOTE><CODE>
<PRE>
mdadd /dev/md0 /dev/disk1 ... /dev/disk(n)
mdrun -p5 /dev/md0
              
</PRE>
</CODE></BLOCKQUOTE>

В случае, если один из дисков отказал, Вы все также должны 
<CODE>mdadd</CODE> их, как и при обычном запуске.
(?? попробуйте использовать /dev/null вместо отказавшего диска ???
и посмотрите, что получится).
После этого массив будет активен в деградированном режиме с (n - 1) 
диском. Если ``<CODE>mdrun</CODE>'' не удается, ядро фиксирует ошибку
(например, несколько отказавших дисков, или неправильное завершение).
Используйте ``<CODE>dmesg</CODE>'' для отображения сообщений об ошибках 
ядра от ``<CODE>mdrun</CODE>''. Если набор raid-5 поврежден исчезновением 
питания, в отличие от отказа диска, можно попробовать создать новый 
RAID суперблок:
<BLOCKQUOTE><CODE>
<PRE>
mkraid -f --only-superblock raid5.conf
            
</PRE>
</CODE></BLOCKQUOTE>

RAID массив не предоставляет защиту от отказа питания или  
краха ядра, и  нельзя гарантировать корректное восстановление.
Воссоздание суперблока приведет к игнорированию 
положения пометкой всех устройств, как ``OK'',
как будто ничего не случилось.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Как работает RAID-5 при отказе диска?

<BLOCKQUOTE>
<B>О</B>:
Типичный рабочий сценарий следующий:
<UL>
<LI>RAID-5 массив активен.
</LI>
<LI>Одно устройство отказывает во время активности массива.
</LI>
<LI>Микропрограмма диска и низкоуровневые драйвера Linux 
диска/контроллера обнаруживают отказ и сообщают код ошибки 
MD драйверу.
</LI>
<LI>MD драйвер продолжает поддерживать безошибочную работу
<CODE>/dev/md0</CODE> устройства для верхних уровней ядра (с 
потерей производительности) используя оставшиеся рабочие
диски.
</LI>
<LI>Системный администратор может, как обычно, 
<CODE>umount /dev/md0</CODE> и <CODE>mdstop /dev/md0</CODE>.
</LI>
<LI>Если отказавшее устройство не заменено, системный 
администратор может запустить массив в деградированном 
режиме, запустив 
<CODE>mdadd</CODE> and <CODE>mdrun</CODE>.</LI>
</UL>
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
<BLOCKQUOTE>
<B>О</B>:
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Почему нет вопроса номер 13?

<BLOCKQUOTE>
<B>О</B>:
Если Вы заботитесь о RAID, Высокой надежности, и UPS,
то, возможно, также хорошая мысль - быть суеверным.
Это не повредит, не так ли? 
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
Я только что заменил отказавший диск в массиве RAID-5.  После пересоздания массива,
<CODE>fsck</CODE> выдает очень много ошибок.  Это нормально?

<BLOCKQUOTE>
<B>О</B>:
Нет. И, если Вы запускали fsck не в "режиме только для чтения; без 
обновлений", вполне возможно, что у Вас повреждены даные.
К несчастью, часто встречающийся сценарий  - 
случайное изменение порядка дисков в массиве RAID-5,
после замены диска.  Хотя суперблок RAID содержит
правильный порядок, не все утилиты используют эту информацию.
В частности, текущая версия <CODE>ckraid</CODE>
будет использовать информацию указанную в <CODE>-f</CODE>
флаге (обычно, файл <CODE>/etc/raid5.conf</CODE>)
вместо данных из суперблока.  Если указанный порядок неверный, 
то замененный диск будет реконструирован неправильно.
Симптом этого - многочисленные ошибки выдаваемые <CODE>fsck</CODE>.

<P>И, если вы удивлены, <B>да</B>, кое-кто потерял  
<B>все</B> свои данные из-за этой ошибки. <B>Настоятельно 
рекомендуется</B> сделать копию <B>всех</B> данных перед 
ре-конфигурированием RAID месива.
</BLOCKQUOTE>

</LI>
<LI><B>В</B>:
В QuickStart сказано, что <CODE>mdstop</CODE> только для того, чтобы 
убедиться, что диски синхронизированы. Это ДЕЙСТВИТЕЛЬНО необходимо? 
Не достачно де-монтирования файловой системы?

<BLOCKQUOTE>
<B>О</B>:
Команда <CODE>mdstop /dev/md0</CODE> будет:
<UL>
<LI>помечать диски как ''чистые''. Это позволит нам обнаружить
неправильное завершение, например из-за отказа питания или
краха ядра.
</LI>
<LI>синхронизирует массив. Это менее важно после де-монтирования
файловой системы, но важно если к <CODE>/dev/md0</CODE>  
был доступ не через файловую систему (например  
посредством <CODE>e2fsck</CODE>).</LI>
</UL>
</BLOCKQUOTE>


</LI>
</OL>
 
<HR>
<A HREF="Software-RAID-HOWTO-2.2-5.html">Next</A>
<A HREF="Software-RAID-HOWTO-2.2-3.html">Previous</A>
<A HREF="Software-RAID-HOWTO-2.2.html#toc4">Contents</A>
</BODY>
</HTML>
